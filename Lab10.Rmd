---
title: "Lab10"
author: "Anna Matarazzo"
date: "11/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}

some_random_means <- rnorm(10,0,1)
t.test(some_random_means, mu=0)

```

```{r}

A_means <- rnorm(10,0,1)
B_means <- rnorm(10,0,1)

t.test(A_means,B_means,paired=TRUE)

```



```{r}
my_data <- data.frame(group = rep(c("A","B"), each=10),
                      means = rnorm(20,0,1))

t.test(means~group, var.equal=TRUE, data=my_data)


```


```{r}

some_random_means <- rnorm(10,0,1)
t.test(some_random_means, mu=0, alternative = "two.sided")

t.test(some_random_means, mu=0, alternative = "less")

```



```{r}

A <- rnorm(10,0,1)
B <- rnorm(10,0,1)
t.test(A,B)

```


```{r}
t.test(A,B, var.equal=TRUE)


```

```{r}
 (my_results <- t.test(A,B, var.equal=TRUE))


my_results$statistic

my_results$parameter

my_results$p.value

my_results$estimate

```

```{r}
library(papaja)
apa_print(my_results)

```

```{r}
N <- 10
# measurements per subject
X <- 2

# distribution assumptions
A_mean <- 100
B_mean <- 100

A_sd <- 25
B_sd <- 25


A_scores <- rnorm(N*X,A_mean,A_sd)
B_scores <- rnorm(N*X,B_mean,B_sd)

sim_data <- data.frame(groups = rep(c("A","B"),each = N*X),
                       subjects = rep(rep(1:N,each = X),2),
                       scores = c(A_scores,B_scores))

library(dplyr)

subject_means <- sim_data %>%
  group_by(groups,subjects) %>%
  summarize(means = mean(scores), .groups = 'drop')

t.test(means~groups, var.equal =TRUE,data = subject_means)



```



```{r}
t.test(replicate(N, mean(rnorm(X, A_mean, A_sd))),
       replicate(N, mean(rnorm(X, B_mean, B_sd))),
       var.equal = TRUE)

```


```{r}
sim_mean_diffs <- replicate(1000, mean(replicate(N, mean(rnorm(X, A_mean, A_sd)))) - mean(replicate(N, mean(rnorm(X, B_mean, B_sd)))))

hist(sim_mean_diffs)

```



```{r}
sim_ts <- replicate(1000, t.test(replicate(N, mean(rnorm(X, A_mean, A_sd))),
                                 replicate(N, mean(rnorm(X, B_mean, B_sd))),
                                 var.equal = TRUE)$statistic)
hist(sim_ts)

```

```{r}

hist(rt(1000,df=18))

```

```{r}

library(ggplot2)
plot_df <- data.frame(values = c(dt(x=seq(-5,5,length.out = 100), df=1),
                                 dt(x=seq(-5,5,length.out = 100), df=3),
                                 dt(x=seq(-5,5,length.out = 100), df=5),
                                 dt(x=seq(-5,5,length.out = 100), df=9),
                                 dt(x=seq(-5,5,length.out = 100), df=11)
                                 ),
                      x = rep(seq(-5,5,length.out = 100),5),
                      df = as.factor(rep(c(1,3,5,9,11), each = 100))
                      )

ggplot(plot_df, aes(x = x, y=values, color=df, group=df))+
  geom_line()+
  ylab("density")+
  xlab("t")+
  scale_x_continuous(breaks=-5:5)

```


```{r}

qnorm(.95,0,1)

qt(p=.95,df=c(1,5,10,100,1000))

```



```{r}

sim_ps <- replicate(1000, t.test(replicate(10, mean(rnorm(5, 0, 1))),
                                 replicate(10, mean(rnorm(5, 0, 1))),
                                 var.equal = TRUE)$p.value)
hist(sim_ps)

length(sim_ps[sim_ps < .05])/1000


```

```{r}
sim_ps <- replicate(1000, t.test(replicate(10, mean(rnorm(5, 0, 1))),
                                 replicate(10, mean(rnorm(5, .25, 1))),
                                 var.equal = TRUE)$p.value)
hist(sim_ps)

length(sim_ps[sim_ps < .05])/1000

```





```{r}
effect_sizes <- seq(0,1.5,.1)
prop_significant <-c()

for(i in 1:length(effect_sizes)){
  sim_ps <- replicate(1000, t.test(replicate(10, mean(rnorm(5, 0, 1))),
                                   replicate(10, mean(rnorm(5, effect_sizes[i], 1))),
                                   var.equal = TRUE)$p.value)

  prop_significant[i] <- length(sim_ps[sim_ps < .05])/1000
}

plot_df <- data.frame(effect_sizes,
                      prop_significant)

ggplot(plot_df, aes(x=effect_sizes,y=prop_significant))+
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks=seq(0,1.5,.1))+
  scale_y_continuous(breaks=seq(0,1,.1)) +
  ylab("Proportion Significant")



```


### Problems

## Problem 1


1. Your task is to obtain the data from the following paper and conduct a reproducible analysis of their results.

Rosenbaum, D., Mama, Y., & Algom, D. (2017). Stand by Your Stroop: Standing Up Enhances Selective Attention and Cognitive Control. Psychological science, 28(12), 1864-1867.

Note, the paper, the data, and an existing reproducible analysis of this data is available at https://crumplab.github.io/statisticsLab/lab-10-factorial-anova.html#important-stuff-4

The re-analysis should focus only on Experiment 3. There are three main goals

1. Reproduce as much of the analysis as possible using only paired-sample t-tests. Note, the authors reported a 2x2 repeated measures ANOVA, but consider how the same questions could be answered by t-tests (2 points)
2. Reproduce a graph of the means, like shown in the paper (2 points)
3. Present a power-curve analysis for the design. (2 points)

```{r}

library(papaja)
library(dplyr)
library(ggplot2)

all_data <- read.csv("Lab_10/stroop_stand.csv")

(stand_stroop <- t.test(all_data$incongruent_stand, all_data$congruent_stand, paired = TRUE))

(sit_stroop <- t.test(all_data$incongruent_sit, all_data$congruent_sit, paired = TRUE))

```

## Original text from the authors results

The Stroop effects in both the sitting condition, M = 118.9 ms, t(49) = 16.52, p < .01, d = 2.376, and the standing condition, M = 95.9 ms, t(49) = 14.327, p < .01, d = 2.034, were highly reliable, but the most significant finding again was the shrinkage of the effect when participants were standing.


## Reproductible report using above re-analysis

The Stroop effects in both the sitting condition, `r papaja::apa_print(sit_stroop)$full_result`, and the standing condition, `r papaja::apa_print(stand_stroop)$full_result`, were highly reliable, but the most significant finding again was the shrinkage of the effect when participants were standing.


```{r}

stand_stroop_scores <- all_data$incongruent_stand-all_data$congruent_stand

sit_stroop_scores <- all_data$incongruent_sit-all_data$congruent_sit

stroop_differences <- sit_stroop_scores - stand_stroop_scores

(paired_results <- t.test(stand_stroop_scores, sit_stroop_scores, paired = TRUE)) 

(interaction_results <- t.test(stroop_differences))

```

## Original text from the authors results

...but the most significant finding again was the shrinkage of the effect when participants were standing, F(1, 49) = 8.964, p = .004, Î·p2 = .155.

## Reproductible report using above re-analysis

We found teh same result using a one-sample t-test, `r apa_print(interaction_results)$full_result`

We found the same mean difference (22.91), and the same p-value (.004). Finally as we will learn later in the course, $t$ is related to $F$, specifically $t^2 = F$, and $2.9941^2 = 8.964$.

## plot


```{r}

library(tidyr)

stroop_df <- all_data %>%
  pivot_longer(cols = 1:4,
               names_to = c("Congruency", "Posture"), names_sep = "_", values_to = "RTs")

overall_means <- stroop_df %>%
  group_by(Posture, Congruency) %>%
  summarise(meanRT = mean(RTs), SEMRT = (sd(RTs)/sqrt(length(RTs))))

ggplot(overall_means, aes(x=Posture,
                          y=meanRT,
                          group=Congruency,
                          fill=Congruency))+
  geom_bar(stat="identity", position = "dodge")+
  theme_classic(base_size = 12)+
  ylab("Mean Reaction Time (ms)")+
  geom_errorbar(aes(ymin=meanRT-SEMRT,
                    ymax=meanRT+SEMRT),
                position=position_dodge(width = 0.9),
                width=0.2,
                color="black")+
  coord_cartesian(ylim = c(500,1000))


```









```{r}

essect_sizes <- seq(0, 1.5, 0.1)
prop_significant <- c()

for(i in 1:length(effect_sizes)){
  sim_ps <- replicate(1000, t.test(replicate(50, rnorm(1, effect_sizes[i], 1)),
                                   mu=0)$p.value)
  
  prop_significant[i] <- length(sim_ps[sim_ps < 0.05])/1000
}

plot_df <- data.frame(effect_sizes, prop_significant)

ggplot(plot_df, aes(x=effect_sizes, y=prop_significant))+
  geom_line()+
  geom_point()+
  scale_x_continuous(breaks = seq(0, 1.5, 0.1))+
  scale_y_continuous(breaks = seq(0, 1, 0.1))+
  ylab("Proportion Significant")

```













